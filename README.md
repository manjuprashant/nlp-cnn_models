
# nlp-cnn_models

# Educational NLP with RNN, LSTM, and GRU

This project demonstrates how to use various Recurrent Neural Network (RNN) architectures to solve two key NLP tasks:
1. **Educational Text Classification** â€” Categorize short educational sentences into subjects (Math, Science, History).
2. **Next Word Generation** â€” Predict the next words in a sentence using trained language models.

---

## ğŸ§  Models Used

- ğŸ” **SimpleRNN**
- ğŸ§  **LSTM (Long Short-Term Memory)**
- âš¡ **GRU (Gated Recurrent Unit)**

Each model is implemented using TensorFlow/Keras and trained on a small educational corpus.

---

## ğŸ“ File Structure





